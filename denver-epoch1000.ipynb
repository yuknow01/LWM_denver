{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ced925-be5b-4bde-be12-01b379b794da",
   "metadata": {},
   "source": [
    "## dataset denver download if you download than pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e19fd3-e6ec-4007-bb2f-2ce81ac1aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Search for scenarios matching criteria\n",
    "scenarios = dm.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58402af8-16ae-47c0-9ed1-5b61727634e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario \"city_18_denver_28\" already exists in /home/dlghdbs200/LWM_denver/deepmimo_scenarios\n"
     ]
    }
   ],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Download a specific scenario\n",
    "dm.download('city_18_denver_28')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227ee19-0b5a-4452-ab65-23776cb56d83",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c343f294-aa27-4eb8-b6bf-44f358940851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import IterableDataset\n",
    "import numpy as np\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from lwm_model import lwm\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "import torch, time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe816b-f8f0-42a4-a1db-26c752132b9b",
   "metadata": {},
   "source": [
    "# dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af341ca-03d3-423d-b26c-4169f2d34e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TXRX PAIR: TXset 1 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 2 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 3 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:03<00:00, 13803.92it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:03<00:00, 13588.59it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:03<00:00, 12163.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Load dataset\n",
    "dataset = dm.load(\"city_18_denver_28\")\n",
    "\n",
    "# Access dataset properties\n",
    "aoa_az = dataset.aoa_az\n",
    "aoa_el = dataset.aoa_el\n",
    "inter_pos = dataset.inter_pos\n",
    "\n",
    "# Compute specific channel information\n",
    "# los = dataset.compute_los()\n",
    "channels = dataset.compute_channels()\n",
    "pl = dataset.compute_pathloss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce33f9-9022-4773-bca7-ef7628975879",
   "metadata": {},
   "source": [
    "# Datashape\n",
    "deepmimo/generator/dataset.py def compute_channels in here channel data shape\n",
    "\n",
    "            numpy.ndarray: MIMO channel matrix with shape [n_users, n_rx_ant, n_tx_ant, n_subcarriers]\n",
    "                          if freq_domain=True, otherwise [n_users, n_rx_ant, n_tx_ant, n_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63259a57-d427-4106-b77a-70fc52058535",
   "metadata": {},
   "source": [
    "# three TxSet(1,2,3) \n",
    "“For 43,248 users, 1 user antenna, 8 BS antennas, and 1 propagation path.”\n",
    "(users, user antenna, BS antennas, PL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823b2047-7527-4d61-bef6-102bafb4385d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43248, 1, 8, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c927c1fa-dad6-4581-ac78-bc2c65b19b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4.0636469e-10-2.4687419e-10j],\n",
       "         [ 4.0486328e-10+2.4921543e-10j],\n",
       "         [-4.0334483e-10-2.5152960e-10j],\n",
       "         ...,\n",
       "         [ 3.9869291e-10+2.5830790e-10j],\n",
       "         [-3.9711204e-10-2.6051203e-10j],\n",
       "         [ 3.9551701e-10+2.6268823e-10j]]],\n",
       "\n",
       "\n",
       "       [[[ 1.5214810e-10-7.0644335e-10j],\n",
       "         [-1.5652508e-10+7.0226053e-10j],\n",
       "         [ 1.6082487e-10-6.9803024e-10j],\n",
       "         ...,\n",
       "         [-1.7325429e-10+6.8506756e-10j],\n",
       "         [ 1.7723865e-10-6.8066053e-10j],\n",
       "         [-1.8114261e-10+6.7621270e-10j]]],\n",
       "\n",
       "\n",
       "       [[[ 7.6910278e-10+1.6763185e-11j],\n",
       "         [-7.6921619e-10-1.8937532e-11j],\n",
       "         [ 7.6933526e-10+2.1130594e-11j],\n",
       "         ...,\n",
       "         [-7.6972168e-10-2.7824850e-11j],\n",
       "         [ 7.6985857e-10+3.0095502e-11j],\n",
       "         [-7.6999856e-10-3.2386184e-11j]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]]],\n",
       "      shape=(43248, 1, 8, 1), dtype=complex64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7a0995-f292-46b0-9f9c-1e11162cceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.0468159e-10-5.8945265e-10j],\n",
       "       [ 2.3423355e-10+4.7612841e-10j],\n",
       "       [-2.8508820e-10-3.6341480e-10j],\n",
       "       [ 4.1828480e-10+3.4321815e-10j],\n",
       "       [-5.3884103e-10-4.4782919e-10j],\n",
       "       [ 5.5945587e-10+6.2805278e-10j],\n",
       "       [-4.5894541e-10-7.8667256e-10j],\n",
       "       [ 2.9558433e-10+8.4439894e-10j]], dtype=complex64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[1][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5b8bf-d6c5-4584-9a92-5e6dbecf8827",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d9cd7-da7a-4695-a61a-5ab7f4f0a58e",
   "metadata": {},
   "source": [
    "## How to predict \n",
    "H1,H2,H3 -> all data union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22876e68-5361-4158-a252-df1ec766095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 97308, Val samples: 32436\n"
     ]
    }
   ],
   "source": [
    "H1, H2, H3 = channels[0], channels[1], channels[2]\n",
    "X = np.concatenate([H1,H2,H3], axis = 0)\n",
    "y = X.copy()\n",
    "\n",
    "\n",
    "# separate real/imaginary\n",
    "X = np.stack([X.real, X.imag], axis=-1).astype(np.float32) # (N,1,8,1,2) add dimension to the back\n",
    "y = np.stack([y.real, y.imag], axis=-1)\n",
    "\n",
    "# 1) Numpy -> Tensor (+ float32) & (optional) per-sample normalization\n",
    "X_t = torch.from_numpy(X).float()\n",
    "y_t = torch.from_numpy(y).float()\n",
    "\n",
    "eps = 1e-8\n",
    "# L2 norm => normalization\n",
    "scale = torch.linalg.vector_norm(X_t.view(X_t.size(0), -1), dim=1, keepdim=True).clamp_min(eps)\n",
    "X_t = X_t / scale.view(-1,1,1,1,1)\n",
    "y_t = y_t / scale.view(-1,1,1,1,1)\n",
    "\n",
    "# 2) Split only by users (inputs=H1,H2; label=H3)\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "N = len(dataset)\n",
    "n_tr = int(N*0.75)         # e.g., 75% train, 25% val\n",
    "n_val = N - n_tr\n",
    "\n",
    "# random seed 42 fixed\n",
    "train_set, val_set = random_split(dataset, [n_tr, n_val], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=2048, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_set)}, Val samples: {len(val_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72097380-6890-4db8-9d76-c99bddb28fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129744, 1, 8, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9729836e-c0b0-4a03-8483-1a59eb33432d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129744, 1, 8, 1, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1190e-f2d5-425a-85eb-e23ffaaa6d5f",
   "metadata": {},
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecce1ee9-1398-4b28-b02c-38cc74a1df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Models (same interface as your run())  [D=2 version]\n",
    "# ============================================================\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden=256, depth=3, pdrop=0.1):\n",
    "        super().__init__()\n",
    "        layers, d = [], 16   # (8 antennas × 2 channels)\n",
    "        for _ in range(depth - 1):\n",
    "            layers += [nn.Linear(d, hidden), nn.ReLU(), nn.Dropout(pdrop)]\n",
    "            d = hidden\n",
    "        layers += [nn.Linear(d, 16)]  # output: (8×2)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 1, 8, 1, 2)\n",
    "        x = x.view(x.size(0), -1)   # (B, 16)\n",
    "        y = self.net(x)             # (B, 16)\n",
    "        return y.view(-1, 1, 8, 1, 2)  # (B, 1, 8, 1, 2)\n",
    "\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv1d(2, 32, 3, padding=1), nn.ReLU(),   # in_channels=2 (real+imag)\n",
    "            nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 3, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),  # (B,64,8) -> (B,64,1)\n",
    "            nn.Flatten(),             # (B,64)\n",
    "            nn.Linear(64, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 16)         # output: (8×2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B, 1, 8, 1, 2)\n",
    "        x = x.squeeze(1).squeeze(-2).permute(0, 2, 1)  # (B, 2, 8)\n",
    "        h = self.feat(x)                               # (B, 64, 8)\n",
    "        y = self.head(h)                               # (B, 16)\n",
    "        return y.view(-1, 1, 8, 1, 2)                  # (B, 1, 8, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ae9def-0c2d-4758-84f7-2f209042dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWM_denver(nn.Module):\n",
    "    def __init__(self, d_model=64, n_layers=12, max_len=129):\n",
    "        super().__init__()\n",
    "        # The actual LWM model (Transformer) will be built later (lazy initialization)\n",
    "        self.core = None\n",
    "\n",
    "        # Store configuration values for later use\n",
    "        # These will be used when building the LWM model dynamically\n",
    "        self.config = {\n",
    "            \"d_model\": d_model,\n",
    "            \"n_layers\": n_layers,\n",
    "            \"max_len\": max_len\n",
    "        }\n",
    "\n",
    "    def build_core(self, L, D, device):\n",
    "        \"\"\"\n",
    "        Build the actual LWM model (\"core\") dynamically when the first input is received.\n",
    "        - L: sequence length (usually equal to the number of Tx antennas)\n",
    "        - D: feature dimension per token (e.g., 2 for real/imag)\n",
    "        - device: which device (CPU/GPU) to place the model on\n",
    "        \"\"\"\n",
    "        self.core = lwm(\n",
    "            element_length=D,                   # Input feature dimension (D=2)\n",
    "            d_model=self.config[\"d_model\"],     # Hidden size of the Transformer\n",
    "            max_len=self.config[\"max_len\"],     # Maximum positional embedding length\n",
    "            n_layers=self.config[\"n_layers\"]    # Number of encoder layers\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Input tensor x shape:\n",
    "            [B, n_rx_ant, n_tx_ant, n_paths, D]\n",
    "        Example: [batch_size, 1, 8, 1, 2]\n",
    "\n",
    "        Steps:\n",
    "        1. Extract B, L (number of Tx antennas), D (feature dimension)\n",
    "        2. Convert 5D input -> 3D sequence [B, L, D]\n",
    "        3. Build the core model if not already created\n",
    "        4. Feed the input into LWM (self.core)\n",
    "        5. Reconstruct back to 5D output shape [B, 1, L, 1, D]\n",
    "        \"\"\"\n",
    "\n",
    "        B, _, L, _, D = x.shape  # (B,1,8,1,2)\n",
    "        x_seq = x.squeeze(1).squeeze(-2).float()  # -> (B, L, D)\n",
    "\n",
    "        # Build the core model only once (lazy initialization)\n",
    "        if self.core is None:\n",
    "            self.build_core(L, D, x.device)\n",
    "\n",
    "        # Generate mask positions for full-sequence prediction\n",
    "        masked_pos = torch.arange(L, device=x.device).unsqueeze(0).repeat(B, 1)  # [B, L]\n",
    "\n",
    "        # Forward pass through the LWM model\n",
    "        y_hat, _ = self.core(x_seq, masked_pos)  # Output: [B, L, D]\n",
    "\n",
    "        # Reshape back to 5D for consistency with MLP/CNN outputs\n",
    "        return y_hat.unsqueeze(1).unsqueeze(-2)  # [B, 1, L, 1, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87433429-9477-4b8f-a1dd-35619b586409",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9229e792-95b4-48a0-b1de-1a579632ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_mse, total_nmse = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            mse = torch.mean((pred - y) ** 2).item()\n",
    "            nmse = mse / torch.mean(y ** 2).item()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_mse += mse * x.size(0)\n",
    "            total_nmse += nmse * x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_rmse = (total_mse / len(dataloader.dataset)) ** 0.5\n",
    "    avg_nmse = total_nmse / len(dataloader.dataset)\n",
    "    avg_nmse_db = 10 * np.log10(avg_nmse + 1e-12)\n",
    "    return avg_loss, avg_rmse, avg_nmse, avg_nmse_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991e24de-b922-4932-a2b4-4b541cf7e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, epochs=150, lr=1e-3, weight_decay=0.0, show_every=1):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_nmse = float(\"inf\")\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_nmse_db = float(\"inf\")\n",
    "\n",
    "    best_epoch_loss = 0\n",
    "    best_epoch_nmse = 0\n",
    "    best_epoch_rmse = 0\n",
    "    best_epoch_nmse_db = 0\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, rmse, nmse, nmse_db = evaluate(model, val_loader, criterion)\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        # Track best values\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch_loss = ep\n",
    "\n",
    "        if nmse < best_nmse:\n",
    "            best_nmse = nmse\n",
    "            best_epoch_nmse = ep\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_epoch_rmse = ep\n",
    "\n",
    "        if nmse_db < best_nmse_db:\n",
    "            best_nmse_db = nmse_db\n",
    "            best_epoch_nmse_db = ep\n",
    "\n",
    "        # Logging\n",
    "        if ep % show_every == 0:\n",
    "            print(f\"[{ep:02d}/{epochs:03d}] \"\n",
    "                  f\"TrainLoss: {train_loss:.6f}  \"\n",
    "                  f\"ValLoss: {val_loss:.6f}  \"\n",
    "                  f\"Val RMSE: {rmse:.4f}  \"\n",
    "                  f\"Val NMSE: {nmse:.4f}  \"\n",
    "                  f\"Val NMSE_dB: {nmse_db:.6f} dB  \"\n",
    "                  f\"TrainTime: {dt:.2f}s\")\n",
    "\n",
    "    # Summary of best metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"=> Best ValLoss   : {best_loss:.6f}   (epoch {best_epoch_loss})\")\n",
    "    print(f\"=> Best Val NMSE  : {best_nmse:.4f}   (epoch {best_epoch_nmse})\")\n",
    "    print(f\"=> Best Val RMSE  : {best_rmse:.4f}   (epoch {best_epoch_rmse})\")\n",
    "    print(f\"=> Best Val NMSE_dB: {best_nmse_db:.4f} dB (epoch {best_epoch_nmse_db})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d40ca9-e4ef-4397-9d25-9730d902a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP Training ===\n",
      "=== Training MLP ===\n",
      "[01/010] TrainLoss: 0.003957  ValLoss: 0.000232  Val RMSE: 0.0152  Val NMSE: 0.0083  Val NMSE_dB: -20.803118 dB  TrainTime: 2.65s\n",
      "[02/010] TrainLoss: 0.001005  ValLoss: 0.000174  Val RMSE: 0.0132  Val NMSE: 0.0062  Val NMSE_dB: -22.044644 dB  TrainTime: 1.71s\n",
      "[03/010] TrainLoss: 0.000907  ValLoss: 0.000168  Val RMSE: 0.0130  Val NMSE: 0.0060  Val NMSE_dB: -22.199927 dB  TrainTime: 1.88s\n",
      "[04/010] TrainLoss: 0.000854  ValLoss: 0.000154  Val RMSE: 0.0124  Val NMSE: 0.0055  Val NMSE_dB: -22.577567 dB  TrainTime: 1.81s\n",
      "[05/010] TrainLoss: 0.000823  ValLoss: 0.000172  Val RMSE: 0.0131  Val NMSE: 0.0062  Val NMSE_dB: -22.108918 dB  TrainTime: 1.75s\n",
      "[06/010] TrainLoss: 0.000808  ValLoss: 0.000180  Val RMSE: 0.0134  Val NMSE: 0.0065  Val NMSE_dB: -21.897462 dB  TrainTime: 1.71s\n",
      "[07/010] TrainLoss: 0.000796  ValLoss: 0.000187  Val RMSE: 0.0137  Val NMSE: 0.0067  Val NMSE_dB: -21.728778 dB  TrainTime: 1.67s\n",
      "[08/010] TrainLoss: 0.000784  ValLoss: 0.000162  Val RMSE: 0.0127  Val NMSE: 0.0058  Val NMSE_dB: -22.373162 dB  TrainTime: 1.93s\n",
      "[09/010] TrainLoss: 0.000768  ValLoss: 0.000223  Val RMSE: 0.0149  Val NMSE: 0.0080  Val NMSE_dB: -20.978032 dB  TrainTime: 1.75s\n",
      "[10/010] TrainLoss: 0.000769  ValLoss: 0.000137  Val RMSE: 0.0117  Val NMSE: 0.0049  Val NMSE_dB: -23.097015 dB  TrainTime: 1.78s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.000137   (epoch 10)\n",
      "=> Best Val NMSE  : 0.0049   (epoch 10)\n",
      "=> Best Val RMSE  : 0.0117   (epoch 10)\n",
      "=> Best Val NMSE_dB: -23.0970 dB (epoch 10)\n",
      "============================================================\n",
      "\n",
      "MLP training log saved to /home/dlghdbs200/LWM_denver/MLP_epoch1000.txt\n",
      "\n",
      "=== CNN Training ===\n",
      "=== Training CNN ===\n",
      "[01/010] TrainLoss: 0.026951  ValLoss: 0.023776  Val RMSE: 0.1542  Val NMSE: 0.8523  Val NMSE_dB: -0.693853 dB  TrainTime: 2.96s\n",
      "[02/010] TrainLoss: 0.017701  ValLoss: 0.014400  Val RMSE: 0.1200  Val NMSE: 0.5162  Val NMSE_dB: -2.871653 dB  TrainTime: 2.05s\n",
      "[03/010] TrainLoss: 0.010962  ValLoss: 0.009071  Val RMSE: 0.0952  Val NMSE: 0.3251  Val NMSE_dB: -4.879173 dB  TrainTime: 1.71s\n",
      "[04/010] TrainLoss: 0.007227  ValLoss: 0.006297  Val RMSE: 0.0794  Val NMSE: 0.2257  Val NMSE_dB: -6.464875 dB  TrainTime: 1.82s\n",
      "[05/010] TrainLoss: 0.004937  ValLoss: 0.004024  Val RMSE: 0.0634  Val NMSE: 0.1442  Val NMSE_dB: -8.409752 dB  TrainTime: 2.72s\n",
      "[06/010] TrainLoss: 0.003254  ValLoss: 0.002689  Val RMSE: 0.0519  Val NMSE: 0.0964  Val NMSE_dB: -10.160344 dB  TrainTime: 2.07s\n",
      "[07/010] TrainLoss: 0.002288  ValLoss: 0.002798  Val RMSE: 0.0529  Val NMSE: 0.1003  Val NMSE_dB: -9.986325 dB  TrainTime: 1.99s\n",
      "[08/010] TrainLoss: 0.001599  ValLoss: 0.001121  Val RMSE: 0.0335  Val NMSE: 0.0402  Val NMSE_dB: -13.959861 dB  TrainTime: 1.92s\n",
      "[09/010] TrainLoss: 0.000737  ValLoss: 0.000517  Val RMSE: 0.0227  Val NMSE: 0.0185  Val NMSE_dB: -17.321007 dB  TrainTime: 1.91s\n",
      "[10/010] TrainLoss: 0.000363  ValLoss: 0.000337  Val RMSE: 0.0183  Val NMSE: 0.0121  Val NMSE_dB: -19.183484 dB  TrainTime: 2.13s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.000337   (epoch 10)\n",
      "=> Best Val NMSE  : 0.0121   (epoch 10)\n",
      "=> Best Val RMSE  : 0.0183   (epoch 10)\n",
      "=> Best Val NMSE_dB: -19.1835 dB (epoch 10)\n",
      "============================================================\n",
      "\n",
      "CNN training log saved to /home/dlghdbs200/LWM_denver/CNN_epoch1000.txt\n",
      "\n",
      "=== LWM Training ===\n",
      "=== Training LWM ===\n",
      "[01/010] TrainLoss: 0.060154  ValLoss: 0.027891  Val RMSE: 0.1670  Val NMSE: 0.9999  Val NMSE_dB: -0.000404 dB  TrainTime: 14.71s\n",
      "[02/010] TrainLoss: 0.027959  ValLoss: 0.019335  Val RMSE: 0.1391  Val NMSE: 0.6932  Val NMSE_dB: -1.591204 dB  TrainTime: 14.55s\n",
      "[03/010] TrainLoss: 0.014339  ValLoss: 0.001511  Val RMSE: 0.0389  Val NMSE: 0.0542  Val NMSE_dB: -12.661591 dB  TrainTime: 13.44s\n",
      "[04/010] TrainLoss: 0.002882  ValLoss: 0.000733  Val RMSE: 0.0271  Val NMSE: 0.0263  Val NMSE_dB: -15.801305 dB  TrainTime: 14.42s\n",
      "[05/010] TrainLoss: 0.001703  ValLoss: 0.000331  Val RMSE: 0.0182  Val NMSE: 0.0119  Val NMSE_dB: -19.250267 dB  TrainTime: 13.67s\n",
      "[06/010] TrainLoss: 0.001277  ValLoss: 0.000243  Val RMSE: 0.0156  Val NMSE: 0.0087  Val NMSE_dB: -20.597892 dB  TrainTime: 13.26s\n",
      "[07/010] TrainLoss: 0.001039  ValLoss: 0.000192  Val RMSE: 0.0138  Val NMSE: 0.0069  Val NMSE_dB: -21.631370 dB  TrainTime: 14.38s\n",
      "[08/010] TrainLoss: 0.000880  ValLoss: 0.000137  Val RMSE: 0.0117  Val NMSE: 0.0049  Val NMSE_dB: -23.078464 dB  TrainTime: 13.29s\n",
      "[09/010] TrainLoss: 0.000762  ValLoss: 0.000108  Val RMSE: 0.0104  Val NMSE: 0.0039  Val NMSE_dB: -24.109559 dB  TrainTime: 14.44s\n",
      "[10/010] TrainLoss: 0.000672  ValLoss: 0.000089  Val RMSE: 0.0094  Val NMSE: 0.0032  Val NMSE_dB: -24.956223 dB  TrainTime: 14.00s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.000089   (epoch 10)\n",
      "=> Best Val NMSE  : 0.0032   (epoch 10)\n",
      "=> Best Val RMSE  : 0.0094   (epoch 10)\n",
      "=> Best Val NMSE_dB: -24.9562 dB (epoch 10)\n",
      "============================================================\n",
      "\n",
      "LWM training log saved to /home/dlghdbs200/LWM_denver/LWM_epoch1000.txt\n"
     ]
    }
   ],
   "source": [
    "import sys, os, contextlib\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 10\n",
    "\n",
    "# --- Tee that mirrors stdout to both console and a file ---\n",
    "class Tee:\n",
    "    def __init__(self, filename, mode=\"w\", encoding=\"utf-8\"):\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        self.file = open(filename, mode, encoding=encoding)\n",
    "        self.stdout = sys.stdout\n",
    "\n",
    "    def write(self, data):\n",
    "        self.file.write(data)\n",
    "        self.stdout.write(data)\n",
    "\n",
    "    def flush(self):\n",
    "        self.file.flush()\n",
    "        self.stdout.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n",
    "    # context manager support\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        self.close()\n",
    "        # don't suppress exceptions\n",
    "        return False\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# \n",
    "base_dir = \"/home/dlghdbs200/LWM_denver\"\n",
    "\n",
    "print(\"=== MLP Training ===\")\n",
    "mlp = MLP(hidden=256, depth=3, pdrop=0.1)\n",
    "mlp_path = os.path.join(base_dir, \"MLP_epoch1000.txt\")\n",
    "with Tee(mlp_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training MLP ===\")\n",
    "        run(mlp, epochs=epochs, lr=2e-3)\n",
    "print(f\"\\nMLP training log saved to {mlp_path}\")\n",
    "\n",
    "print(\"\\n=== CNN Training ===\")\n",
    "cnn = CNN1D()\n",
    "cnn_path = os.path.join(base_dir, \"CNN_epoch1000.txt\")\n",
    "with Tee(cnn_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training CNN ===\")\n",
    "        run(cnn, epochs=epochs, lr=1e-3)\n",
    "print(f\"\\nCNN training log saved to {cnn_path}\")\n",
    "\n",
    "print(\"\\n=== LWM Training ===\")\n",
    "\n",
    "lwm_model = LWM_denver(d_model=64, n_layers=12)\n",
    "lwm_path = os.path.join(base_dir, \"LWM_epoch1000.txt\")\n",
    "with Tee(lwm_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training LWM ===\")\n",
    "        sample_x, _ = next(iter(train_loader))\n",
    "        L = sample_x.shape[2]\n",
    "        D = sample_x.shape[-1]\n",
    "        lwm_model.build_core(L=L, D=D, device=device)\n",
    "        run(lwm_model, epochs=epochs, lr=1e-3)\n",
    "print(f\"\\nLWM training log saved to {lwm_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b77083-7fa4-4130-b39b-f0c02ab89563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37d79d-48c8-444b-8824-a6aadacefd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2dfb2-cd58-4c80-99e6-890704b38743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93e676-37f4-4d42-b20b-98e7209e7116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b6e34-fbab-4796-b7e0-82d4b0b9472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c057e8-c736-4478-a511-60c77733e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
