{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ced925-be5b-4bde-be12-01b379b794da",
   "metadata": {},
   "source": [
    "## dataset denver download if you download than pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea5f9b0-cf35-48ec-aa33-dc418cd832b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepmimo in /home/dlghdbs200/.local/lib/python3.10/site-packages (4.0.0b10)\n",
      "Requirement already satisfied: scipy>=1.6.2 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from deepmimo) (1.15.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepmimo) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from deepmimo) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.8.2 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from deepmimo) (3.10.3)\n",
      "Requirement already satisfied: numpy<2.3,>=1.19.5 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from deepmimo) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.2->deepmimo) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.8.2->deepmimo) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from matplotlib>=3.8.2->deepmimo) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from matplotlib>=3.8.2->deepmimo) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from matplotlib>=3.8.2->deepmimo) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from matplotlib>=3.8.2->deepmimo) (4.58.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.2->deepmimo) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in /home/dlghdbs200/.local/lib/python3.10/site-packages (from matplotlib>=3.8.2->deepmimo) (11.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepmimo) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->deepmimo) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->deepmimo) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->deepmimo) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.2->deepmimo) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepmimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e19fd3-e6ec-4007-bb2f-2ce81ac1aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Search for scenarios matching criteria\n",
    "scenarios = dm.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58402af8-16ae-47c0-9ed1-5b61727634e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario \"city_18_denver_28\" already exists in /home/dlghdbs200/LWM_denver/deepmimo_scenarios\n"
     ]
    }
   ],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Download a specific scenario\n",
    "dm.download('city_18_denver_28')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227ee19-0b5a-4452-ab65-23776cb56d83",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c343f294-aa27-4eb8-b6bf-44f358940851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import IterableDataset\n",
    "import numpy as np\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from lwm_model import lwm\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "import torch, time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49d9ec5-08f0-4f80-a3d8-5e1700b9f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe816b-f8f0-42a4-a1db-26c752132b9b",
   "metadata": {},
   "source": [
    "# dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af341ca-03d3-423d-b26c-4169f2d34e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TXRX PAIR: TXset 1 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 2 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 3 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 28977.07it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 28018.75it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 29246.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Load dataset\n",
    "dataset = dm.load(\"city_18_denver_28\")\n",
    "\n",
    "# Access dataset properties\n",
    "aoa_az = dataset.aoa_az\n",
    "aoa_el = dataset.aoa_el\n",
    "inter_pos = dataset.inter_pos\n",
    "\n",
    "# Compute specific channel information\n",
    "# los = dataset.compute_los()\n",
    "channels = dataset.compute_channels()\n",
    "pl = dataset.compute_pathloss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce33f9-9022-4773-bca7-ef7628975879",
   "metadata": {},
   "source": [
    "# Datashape\n",
    "deepmimo/generator/dataset.py def compute_channels in here channel data shape\n",
    "\n",
    "            numpy.ndarray: MIMO channel matrix with shape [n_users, n_rx_ant, n_tx_ant, n_subcarriers]\n",
    "                          if freq_domain=True, otherwise [n_users, n_rx_ant, n_tx_ant, n_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63259a57-d427-4106-b77a-70fc52058535",
   "metadata": {},
   "source": [
    "# three TxSet(1,2,3) \n",
    "“For 43,248 users, 1 user antenna, 8 BS antennas, and 1 propagation path.”\n",
    "(users, user antenna, BS antennas, PL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823b2047-7527-4d61-bef6-102bafb4385d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43248, 1, 8, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c927c1fa-dad6-4581-ac78-bc2c65b19b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4.0636469e-10-2.4687419e-10j],\n",
       "         [ 4.0486328e-10+2.4921543e-10j],\n",
       "         [-4.0334483e-10-2.5152960e-10j],\n",
       "         ...,\n",
       "         [ 3.9869291e-10+2.5830790e-10j],\n",
       "         [-3.9711204e-10-2.6051203e-10j],\n",
       "         [ 3.9551701e-10+2.6268823e-10j]]],\n",
       "\n",
       "\n",
       "       [[[ 1.5214810e-10-7.0644335e-10j],\n",
       "         [-1.5652508e-10+7.0226053e-10j],\n",
       "         [ 1.6082487e-10-6.9803024e-10j],\n",
       "         ...,\n",
       "         [-1.7325429e-10+6.8506756e-10j],\n",
       "         [ 1.7723865e-10-6.8066053e-10j],\n",
       "         [-1.8114261e-10+6.7621270e-10j]]],\n",
       "\n",
       "\n",
       "       [[[ 7.6910278e-10+1.6763185e-11j],\n",
       "         [-7.6921619e-10-1.8937532e-11j],\n",
       "         [ 7.6933526e-10+2.1130594e-11j],\n",
       "         ...,\n",
       "         [-7.6972168e-10-2.7824850e-11j],\n",
       "         [ 7.6985857e-10+3.0095502e-11j],\n",
       "         [-7.6999856e-10-3.2386184e-11j]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         ...,\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j],\n",
       "         [ 0.0000000e+00+0.0000000e+00j]]]],\n",
       "      shape=(43248, 1, 8, 1), dtype=complex64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7a0995-f292-46b0-9f9c-1e11162cceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channels[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2832596c-936e-402e-b9db-70a75e79c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3398023e-09-1.4365638e-09j], dtype=complex64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels[1][2][0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5b8bf-d6c5-4584-9a92-5e6dbecf8827",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d9cd7-da7a-4695-a61a-5ab7f4f0a58e",
   "metadata": {},
   "source": [
    "## How to predict \n",
    "H1,H2,H3 -> all data union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22876e68-5361-4158-a252-df1ec766095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 97308, Val samples: 32436\n"
     ]
    }
   ],
   "source": [
    "H1, H2, H3 = channels[0], channels[1], channels[2]\n",
    "X = np.concatenate([H1,H2,H3], axis = 0)\n",
    "y = X.copy()\n",
    "\n",
    "\n",
    "# separate real/imaginary\n",
    "X = np.stack([X.real, X.imag], axis=-1).astype(np.float32) # (N,1,8,1,2) add dimension to the back\n",
    "y = np.stack([y.real, y.imag], axis=-1)\n",
    "\n",
    "# 1) Numpy -> Tensor (+ float32) & (optional) per-sample normalization\n",
    "X_t = torch.from_numpy(X).float()\n",
    "y_t = torch.from_numpy(y).float()\n",
    "\n",
    "eps = 1e-8\n",
    "# L2 norm => normalization\n",
    "scale = torch.linalg.vector_norm(X_t.view(X_t.size(0), -1), dim=1, keepdim=True).clamp_min(eps)\n",
    "X_t = X_t / scale.view(-1,1,1,1,1)\n",
    "y_t = y_t / scale.view(-1,1,1,1,1)\n",
    "\n",
    "# 2) Split only by users (inputs=H1,H2; label=H3)\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "N = len(dataset)\n",
    "n_tr = int(N*0.75)         # e.g., 75% train, 25% val\n",
    "n_val = N - n_tr\n",
    "\n",
    "# random seed 42 fixed\n",
    "train_set, val_set = random_split(dataset, [n_tr, n_val], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=2048, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_set)}, Val samples: {len(val_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72097380-6890-4db8-9d76-c99bddb28fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129744, 1, 8, 1, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9729836e-c0b0-4a03-8483-1a59eb33432d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129744, 1, 8, 1, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fc006b-a516-434d-967a-5f842642139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.3372,  0.0823]],\n",
       " \n",
       "          [[ 0.3120,  0.0524]],\n",
       " \n",
       "          [[-0.3008, -0.1282]],\n",
       " \n",
       "          [[ 0.2441,  0.2517]],\n",
       " \n",
       "          [[-0.1549, -0.2929]],\n",
       " \n",
       "          [[ 0.0792,  0.3708]],\n",
       " \n",
       "          [[ 0.0843, -0.3778]],\n",
       " \n",
       "          [[-0.1843,  0.3351]]]]),\n",
       " tensor([[[[-0.3372,  0.0823]],\n",
       " \n",
       "          [[ 0.3120,  0.0524]],\n",
       " \n",
       "          [[-0.3008, -0.1282]],\n",
       " \n",
       "          [[ 0.2441,  0.2517]],\n",
       " \n",
       "          [[-0.1549, -0.2929]],\n",
       " \n",
       "          [[ 0.0792,  0.3708]],\n",
       " \n",
       "          [[ 0.0843, -0.3778]],\n",
       " \n",
       "          [[-0.1843,  0.3351]]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[12000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1190e-f2d5-425a-85eb-e23ffaaa6d5f",
   "metadata": {},
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecce1ee9-1398-4b28-b02c-38cc74a1df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Models (same interface as your run())  [D=2 version]\n",
    "# ============================================================\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden=256, depth=3, pdrop=0.1):\n",
    "        super().__init__()\n",
    "        layers, d = [], 16   # (8 antennas × 2 channels)\n",
    "        for _ in range(depth - 1):\n",
    "            layers += [nn.Linear(d, hidden), nn.ReLU(), nn.Dropout(pdrop)]\n",
    "            d = hidden\n",
    "        layers += [nn.Linear(d, 16)]  # output: (8×2)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 1, 8, 1, 2)\n",
    "        x = x.view(x.size(0), -1)   # (B, 16)\n",
    "        y = self.net(x)             # (B, 16)\n",
    "        return y.view(-1, 1, 8, 1, 2)  # (B, 1, 8, 1, 2)\n",
    "\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv1d(2, 32, 3, padding=1), nn.ReLU(),   # in_channels=2 (real+imag)\n",
    "            nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 3, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),  # (B,64,8) -> (B,64,1)\n",
    "            nn.Flatten(),             # (B,64)\n",
    "            nn.Linear(64, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 16)         # output: (8×2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B, 1, 8, 1, 2)\n",
    "        x = x.squeeze(1).squeeze(-2).permute(0, 2, 1)  # (B, 2, 8)\n",
    "        h = self.feat(x)                               # (B, 64, 8)\n",
    "        y = self.head(h)                               # (B, 16)\n",
    "        return y.view(-1, 1, 8, 1, 2)                  # (B, 1, 8, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4ae9def-0c2d-4758-84f7-2f209042dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWM_denver(nn.Module):\n",
    "    def __init__(self, d_model=64, n_layers=12, max_len=129):\n",
    "        super().__init__()\n",
    "        # The actual LWM model (Transformer) will be built later (lazy initialization)\n",
    "        self.core = None\n",
    "\n",
    "        # Store configuration values for later use\n",
    "        # These will be used when building the LWM model dynamically\n",
    "        self.config = {\n",
    "            \"d_model\": d_model,\n",
    "            \"n_layers\": n_layers,\n",
    "            \"max_len\": max_len\n",
    "        }\n",
    "\n",
    "    def build_core(self, L, D, device):\n",
    "        \"\"\"\n",
    "        Build the actual LWM model (\"core\") dynamically when the first input is received.\n",
    "        - L: sequence length (usually equal to the number of Tx antennas)\n",
    "        - D: feature dimension per token (e.g., 2 for real/imag)\n",
    "        - device: which device (CPU/GPU) to place the model on\n",
    "        \"\"\"\n",
    "        self.core = lwm(\n",
    "            element_length=D,                   # Input feature dimension (D=2)\n",
    "            d_model=self.config[\"d_model\"],     # Hidden size of the Transformer\n",
    "            max_len=self.config[\"max_len\"],     # Maximum positional embedding length\n",
    "            n_layers=self.config[\"n_layers\"]    # Number of encoder layers\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x, **kargs):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Input tensor x shape:\n",
    "            [B, n_rx_ant, n_tx_ant, n_paths, D]\n",
    "        Example: [batch_size, 1, 8, 1, 2]\n",
    "\n",
    "        Steps:\n",
    "        1. Extract B, L (number of Tx antennas), D (feature dimension)\n",
    "        2. Convert 5D input -> 3D sequence [B, L, D]\n",
    "        3. Build the core model if not already created\n",
    "        4. Feed the input into LWM (self.core)\n",
    "        5. Reconstruct back to 5D output shape [B, 1, L, 1, D]\n",
    "        \"\"\"\n",
    "\n",
    "        B, _, L, _, D = x.shape  # (B,1,8,1,2)\n",
    "        x_seq = x.squeeze(1).squeeze(-2).float()  # -> (B, L, D)\n",
    "        \n",
    "\n",
    "        # Build the core model only once (lazy initialization)\n",
    "        if self.core is None:\n",
    "            self.build_core(L, D, x.device)\n",
    "\n",
    "        # Generate mask positions for full-sequence prediction\n",
    "        masked_pos = torch.arange(L, device=x.device).unsqueeze(0).repeat(B, 1)  # [B, L]\n",
    "\n",
    "        # Forward pass through the LWM model\n",
    "        y_hat, _ = self.core(x_seq, masked_pos)  # Output: [B, L, D]\n",
    "\n",
    "        # Reshape back to 5D for consistency with MLP/CNN outputs\n",
    "        return y_hat.unsqueeze(1).unsqueeze(-2)  # [B, 1, L, 1, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87433429-9477-4b8f-a1dd-35619b586409",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9229e792-95b4-48a0-b1de-1a579632ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_mse, total_nmse = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            mse = torch.mean((pred - y) ** 2).item()\n",
    "            nmse = mse / torch.mean(y ** 2).item()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_mse += mse * x.size(0)\n",
    "            total_nmse += nmse * x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_rmse = (total_mse / len(dataloader.dataset)) ** 0.5\n",
    "    avg_nmse = total_nmse / len(dataloader.dataset)\n",
    "    avg_nmse_db = 10 * np.log10(avg_nmse + 1e-12)\n",
    "    return avg_loss, avg_rmse, avg_nmse, avg_nmse_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991e24de-b922-4932-a2b4-4b541cf7e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, epochs=150, lr=1e-3, weight_decay=0.0, show_every=1):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_nmse = float(\"inf\")\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_nmse_db = float(\"inf\")\n",
    "\n",
    "    best_epoch_loss = 0\n",
    "    best_epoch_nmse = 0\n",
    "    best_epoch_rmse = 0\n",
    "    best_epoch_nmse_db = 0\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, rmse, nmse, nmse_db = evaluate(model, val_loader, criterion)\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        # Track best values\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch_loss = ep\n",
    "\n",
    "        if nmse < best_nmse:\n",
    "            best_nmse = nmse\n",
    "            best_epoch_nmse = ep\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_epoch_rmse = ep\n",
    "\n",
    "        if nmse_db < best_nmse_db:\n",
    "            best_nmse_db = nmse_db\n",
    "            best_epoch_nmse_db = ep\n",
    "\n",
    "        # Logging\n",
    "        if ep % show_every == 0:\n",
    "            print(f\"[{ep:02d}/{epochs:03d}] \"\n",
    "                  f\"TrainLoss: {train_loss:.6f}  \"\n",
    "                  f\"ValLoss: {val_loss:.6f}  \"\n",
    "                  f\"Val RMSE: {rmse:.4f}  \"\n",
    "                  f\"Val NMSE: {nmse:.4f}  \"\n",
    "                  f\"Val NMSE_dB: {nmse_db:.6f} dB  \"\n",
    "                  f\"TrainTime: {dt:.2f}s\")\n",
    "\n",
    "    # Summary of best metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"=> Best ValLoss   : {best_loss:.6f}   (epoch {best_epoch_loss})\")\n",
    "    print(f\"=> Best Val NMSE  : {best_nmse:.4f}   (epoch {best_epoch_nmse})\")\n",
    "    print(f\"=> Best Val RMSE  : {best_rmse:.4f}   (epoch {best_epoch_rmse})\")\n",
    "    print(f\"=> Best Val NMSE_dB: {best_nmse_db:.4f} dB (epoch {best_epoch_nmse_db})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95d40ca9-e4ef-4397-9d25-9730d902a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP Training ===\n",
      "=== Training MLP ===\n",
      "[01/001] TrainLoss: 0.005963  ValLoss: 0.000313  Val RMSE: 0.0177  Val NMSE: 0.0112  Val NMSE_dB: -19.504991 dB  TrainTime: 1.11s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.000313   (epoch 1)\n",
      "=> Best Val NMSE  : 0.0112   (epoch 1)\n",
      "=> Best Val RMSE  : 0.0177   (epoch 1)\n",
      "=> Best Val NMSE_dB: -19.5050 dB (epoch 1)\n",
      "============================================================\n",
      "\n",
      "MLP training log saved to /home/dlghdbs200/LWM_denver/MLP_epoch1_user.txt\n",
      "\n",
      "=== CNN Training ===\n",
      "=== Training CNN ===\n",
      "[01/001] TrainLoss: 0.026234  ValLoss: 0.020826  Val RMSE: 0.1443  Val NMSE: 0.7466  Val NMSE_dB: -1.269141 dB  TrainTime: 1.25s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.020826   (epoch 1)\n",
      "=> Best Val NMSE  : 0.7466   (epoch 1)\n",
      "=> Best Val RMSE  : 0.1443   (epoch 1)\n",
      "=> Best Val NMSE_dB: -1.2691 dB (epoch 1)\n",
      "============================================================\n",
      "\n",
      "CNN training log saved to /home/dlghdbs200/LWM_denver/CNN_epoch1_user.txt\n",
      "\n",
      "=== LWM Training ===\n",
      "=== Training LWM ===\n",
      "[01/001] TrainLoss: 0.050083  ValLoss: 0.027896  Val RMSE: 0.1670  Val NMSE: 1.0001  Val NMSE_dB: 0.000407 dB  TrainTime: 7.14s\n",
      "============================================================\n",
      "=> Best ValLoss   : 0.027896   (epoch 1)\n",
      "=> Best Val NMSE  : 1.0001   (epoch 1)\n",
      "=> Best Val RMSE  : 0.1670   (epoch 1)\n",
      "=> Best Val NMSE_dB: 0.0004 dB (epoch 1)\n",
      "============================================================\n",
      "\n",
      "LWM training log saved to /home/dlghdbs200/LWM_denver/LWM_epoch1_user.txt\n"
     ]
    }
   ],
   "source": [
    "import sys, os, contextlib\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 1\n",
    "\n",
    "# --- Tee that mirrors stdout to both console and a file ---\n",
    "class Tee:\n",
    "    def __init__(self, filename, mode=\"w\", encoding=\"utf-8\"):\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        self.file = open(filename, mode, encoding=encoding)\n",
    "        self.stdout = sys.stdout\n",
    "\n",
    "    def write(self, data):\n",
    "        self.file.write(data)\n",
    "        self.stdout.write(data)\n",
    "\n",
    "    def flush(self):\n",
    "        self.file.flush()\n",
    "        self.stdout.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n",
    "    # context manager support\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        self.close()\n",
    "        # don't suppress exceptions\n",
    "        return False\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# \n",
    "base_dir = \"/home/dlghdbs200/LWM_denver\"\n",
    "\n",
    "print(\"=== MLP Training ===\")\n",
    "mlp = MLP(hidden=256, depth=3, pdrop=0.1)\n",
    "mlp_path = os.path.join(base_dir, \"MLP_epoch1_user.txt\")\n",
    "with Tee(mlp_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training MLP ===\")\n",
    "        run(mlp, epochs=epochs, lr=1e-3)\n",
    "print(f\"\\nMLP training log saved to {mlp_path}\")\n",
    "\n",
    "print(\"\\n=== CNN Training ===\")\n",
    "cnn = CNN1D()\n",
    "cnn_path = os.path.join(base_dir, \"CNN_epoch1_user.txt\")\n",
    "with Tee(cnn_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training CNN ===\")\n",
    "        run(cnn, epochs=epochs, lr=1e-3)\n",
    "print(f\"\\nCNN training log saved to {cnn_path}\")\n",
    "\n",
    "print(\"\\n=== LWM Training ===\")\n",
    "\n",
    "lwm_model = LWM_denver(d_model=64, n_layers=12)\n",
    "lwm_path = os.path.join(base_dir, \"LWM_epoch1_user.txt\")\n",
    "with Tee(lwm_path, \"w\") as tee:\n",
    "    with contextlib.redirect_stdout(tee):\n",
    "        print(\"=== Training LWM ===\")\n",
    "        sample_x, _ = next(iter(train_loader))\n",
    "        L = sample_x.shape[2]\n",
    "        D = sample_x.shape[-1]\n",
    "        lwm_model.build_core(L=L, D=D, device=device)\n",
    "        run(lwm_model, epochs=epochs, lr=1e-3)\n",
    "print(f\"\\nLWM training log saved to {lwm_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a949fef2-2c4c-4095-ae30-3fd449b4f272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1, 8, 1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd94bb-9867-4fb0-bbf5-0ac7bc61640d",
   "metadata": {},
   "source": [
    "# inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a87bc35c-e851-46bd-980f-12cc51629474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TXRX PAIR: TXset 1 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 2 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n",
      "Loading TXRX PAIR: TXset 3 (tx_idx 0) & RXset 0 (rx_idxs 43248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 27932.21it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 24921.66it/s]\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████| 43248/43248 [00:01<00:00, 30567.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import deepmimo as dm\n",
    "\n",
    "# Load dataset\n",
    "dataset = dm.load(\"city_18_denver_28\")\n",
    "\n",
    "# Access dataset properties\n",
    "aoa_az = dataset.aoa_az\n",
    "aoa_el = dataset.aoa_el\n",
    "inter_pos = dataset.inter_pos\n",
    "\n",
    "# Compute specific channel information\n",
    "# los = dataset.compute_los()\n",
    "channels = dataset.compute_channels()\n",
    "pl = dataset.compute_pathloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "962681a7-0331-4b2f-a9c2-0d73967c6ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 97308, Val samples: 32436\n"
     ]
    }
   ],
   "source": [
    "H1, H2, H3 = channels[0], channels[1], channels[2]\n",
    "X = np.concatenate([H1,H2,H3], axis = 0)\n",
    "y = X.copy()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# separate real/imaginary\n",
    "X = np.stack([X.real, X.imag], axis=-1).astype(np.float32) # (N,1,8,1,2) add dimension to the back\n",
    "y = np.stack([y.real, y.imag], axis=-1)\n",
    "\n",
    "# 1) Numpy -> Tensor (+ float32) & (optional) per-sample normalization\n",
    "X_t = torch.from_numpy(X).float()\n",
    "y_t = torch.from_numpy(y).float()\n",
    "\n",
    "eps = 1e-8\n",
    "# L2 norm => normalization\n",
    "scale = torch.linalg.vector_norm(X_t.view(X_t.size(0), -1), dim=1, keepdim=True).clamp_min(eps)\n",
    "X_t = X_t / scale.view(-1,1,1,1,1)\n",
    "y_t = y_t / scale.view(-1,1,1,1,1)\n",
    "\n",
    "# 2) Split only by users (inputs=H1,H2; label=H3)\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "N = len(dataset)\n",
    "n_tr = int(N*0.75)         # e.g., 75% train, 25% val\n",
    "n_val = N - n_tr\n",
    "\n",
    "# random seed 42 fixed\n",
    "train_set, val_set = random_split(dataset, [n_tr, n_val], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=2048, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_set)}, Val samples: {len(val_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2e2dfb2-cd58-4c80-99e6-890704b38743",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_single, y_single = val_set[0]\n",
    "#x_single.shape [1,8,1,2]\n",
    "x_single = x_single.unsqueeze(0).to(device)\n",
    "y_single = y_single.unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0010989b-a534-47a5-851a-c3c20c8c2ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Inference time (1 sample): 0.254 ms\n",
      "[CNN1D] Inference time (1 sample): 0.702 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure CUDA is available\n",
    "assert torch.cuda.is_available()\n",
    "device = \"cuda\"\n",
    "\n",
    "# Prepare one input sample (already preprocessed)\n",
    "# Shape: (1, 1, 8, 1, 2)\n",
    "x_gpu = x_single.to(device)\n",
    "\n",
    "# Initialize models\n",
    "mlp = MLP().to(device).eval()\n",
    "cnn = CNN1D().to(device).eval()\n",
    "\n",
    "def measure_inference_time(model, x_gpu, name=\"Model\", warmup=10):\n",
    "    \"\"\"Measure single inference latency with GPU warm-up\"\"\"\n",
    "    # --- Warm-up (stabilize GPU kernels and cache) ---\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x_gpu)\n",
    "    torch.cuda.synchronize()  # ensure warm-up finished\n",
    "\n",
    "    # --- Actual timing ---\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_event.record()\n",
    "        _ = model(x_gpu)     # Forward pass\n",
    "        end_event.record()\n",
    "\n",
    "    torch.cuda.synchronize()  # wait for GPU ops to complete\n",
    "    elapsed_ms = start_event.elapsed_time(end_event)  # milliseconds\n",
    "    print(f\"[{name}] Inference time (1 sample): {elapsed_ms:.3f} ms\")\n",
    "\n",
    "# Run inference timing for each model\n",
    "measure_inference_time(mlp, x_gpu, name=\"MLP\")\n",
    "measure_inference_time(cnn, x_gpu, name=\"CNN1D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51ff2eab-4e21-45d8-8acf-51bb0583279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LWM_denver] Inference time (1 sample): 11.844 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure CUDA is available\n",
    "assert torch.cuda.is_available()\n",
    "device = \"cuda\"\n",
    "\n",
    "# Prepare one input sample\n",
    "# Shape: (1, 1, 8, 1, 2)\n",
    "x_gpu = x_single.to(device)\n",
    "\n",
    "# Initialize model\n",
    "lwm_model = LWM_denver(d_model=64, n_layers=12).to(device).eval()\n",
    "\n",
    "# Build core manually (since LWM_denver uses lazy initialization)\n",
    "L = x_gpu.shape[2]   # number of Tx antennas (sequence length)\n",
    "D = x_gpu.shape[-1]  # feature dimension per token (real/imag)\n",
    "lwm_model.build_core(L=L, D=D, device=device)\n",
    "\n",
    "def measure_inference_time(model, x_gpu, name=\"Model\", warmup=10):\n",
    "    \"\"\"Measure single inference latency with GPU warm-up\"\"\"\n",
    "    # --- Warm-up ---\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # --- Timing ---\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event   = torch.cuda.Event(enable_timing=True)\n",
    "    with torch.no_grad():\n",
    "        start_event.record()\n",
    "        _ = model(x_gpu)\n",
    "        end_event.record()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_ms = start_event.elapsed_time(end_event)\n",
    "    print(f\"[{name}] Inference time (1 sample): {elapsed_ms:.3f} ms\")\n",
    "\n",
    "# Run inference timing\n",
    "measure_inference_time(lwm_model, x_gpu, name=\"LWM_denver\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516c7f4-c321-40d6-871e-aa689e439a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
